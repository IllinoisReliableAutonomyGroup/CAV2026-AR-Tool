\section{Discussion and Conclusion}
\label{sec:discusion}

The verification criterion adopted in this work is inherently conservative, arising from multiple sources of over-approximation, including abstraction errors introduced by the abstract rendering pipeline, relaxations incurred when linear bounds are converted into interval bounds, and the incorporation of pose cell width into the certification metric. Although employing finer partitions can mitigate abstraction error, this approach incurs increased computational cost. A promising future direction is to enable end-to-end linear bound propagation throughout the entire pipeline, which would remove intermediate interval relaxations and decouple the certification metric from pose cell width, thereby enabling substantially tighter certification results.

Scalability constitutes another important avenue for future improvement, particularly in the context of large-scale scenes and higher-resolution images. As scene complexity and image resolution increase, the computational cost of both abstract rendering and bound propagation grows rapidly. This observation motivates the development of more efficient abstract rendering techniques beyond linear bound propagation, which could significantly reduce computational overhead while preserving certification tightness.

Finally, the proposed framework currently assumes that the reconstructed 3D Gaussian Splatting (3DGS) scene provides an accurate approximation of the real environment. In practice, however, reconstruction errors are unavoidable. Recent studies\cite{goli2024bayes} have begun to quantify uncertainty in reconstructed scene representations. Incorporating such scene-level uncertainty into the abstract rendering process represents an important future direction, as it would enable end-to-end robustness guarantees that jointly account for uncertainties arising from both imperfect scene reconstruction and camera pose variation.

Overall, this work establishes a practical and extensible foundation for verifying vision-based pose estimation in large-scale, photorealistic 3D environments. By enabling certified robustness analysis of a GateNet-based pipeline on 3D Gaussian Splatting scenes with up to 500k Gaussians, and by releasing a standardized benchmark, our toolkit allows systematic study of tighter end-to-end bound propagation, more scalable abstract rendering methods, and integration of scene-level uncertainty within a unified verification framework.
