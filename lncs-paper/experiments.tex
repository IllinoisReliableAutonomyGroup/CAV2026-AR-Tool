\section{Experimental Results}
\label{sec:experiments}

We evaluate the \emph{Abstract Rendering Toolkit (ART)} for verifying the robustness of a pretrained GateNet-based pose estimator across four drone racing tracks constructed in a 3D Gaussian Splatting (3DGS) environment using \emph{FalconGym}~\cite{falcon}. The four tracks consist of racing gates arranged in distinct layouts: (1) a straight track(3 gates), (2) a circular track(4 gates), (3) a lemniscate track(5 gates), and (4) an arc-shaped track(4 gates).

For each track, nominal flight trajectories are generated using \emph{Kochanek--Bartels (TCB) splines}~\cite{kochanek1984interpolating}, given the start pose, end pose, and the poses of the gates. The spline is discretized into a sequence of waypoints with a fixed spatial resolution of $\Delta t = 5\,\mathrm{cm}$.

Around each waypoint, we define a local perturbation region parameterized as a cylindrical set with dimensions $(d, r, \theta)$, corresponding to height, radial displacement, and angular deviation, respectively. The cylinder height is defined by the vector from the current waypoint to the subsequent waypoint along the nominal trajectory. A rotation matrix $R$ is constructed such that the forward direction of the waypoint aligns with the vector pointing toward the center of the next gate, ensuring that the gate remains within the camera’s field of view. The angular range spans the full circle, i.e., $\theta \in [0, 2\pi)$.

The cylinder radius is adaptively determined based on the waypoint’s relative distance to neighboring gates: it is smaller when the waypoint lies closer to a gate and larger when it is farther from both the preceding and subsequent gates. Collectively, the pose space along a trajectory forms a tube-shaped region with a total length ranging from 5 to 10 meters and a radius between 0.1 and 0.2 meters.

For rendering, we use images with a resolution of $(64, 64, 3)$. The 3DGS scene representation is trained using \emph{Nerfstudio}~\cite{nerfstudio}. Each scene contains approximately 470k Gaussians, while each gate is modeled by roughly 3k Gaussians.

The \emph{Bound GateNet} model is trained by sampling 1{,}000 poses from the defined pose space. The network takes an abstract image tensor of shape $(3, 64, 64)$ as input and outputs a three-dimensional vector representing the relative pose from the current waypoint to the center of the next gate, expressed in the waypoint coordinate frame. The estimated pose in the world coordinate frame is obtained by applying the corresponding rotation matrix $R$.

After computing abstract images, they are fed into Bound GateNet to obtain interval bounds on the estimated pose. If the maximum deviation between the estimated pose interval and the input pose interval is below a predefined threshold of 10\,cm, the network is considered \emph{certified} over that pose region and is visualized in green. Otherwise, the region is marked in red, indicating a potential violation where the estimated pose may deviate beyond the allowed threshold.

\sayan{Describe the different inputs at an appropriate level of detail. Not all numbers need to be spelled out.}

\sayan{Show qualitative results with the 3Dplots}

\sayan{Main takeaways. What are they and how do you justify them?}

\section{Conclusion}
\label{sec:conclusion}
\sayan{Write later.}

Future directions: Linear set representations for tighter bounds. 


\bibliographystyle{splncs04}
\bibliography{egbib}