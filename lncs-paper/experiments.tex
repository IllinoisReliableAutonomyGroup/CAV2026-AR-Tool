\section{Experimental Evaluation}
\label{sec:experiments}

\paragraph{The racing benchmark.} We evaluate the \emph{Abstract Rendering Toolkit (ART)} by verifying the robustness of a pretrained GateNet-based pose estimator across four drone racing tracks constructed in the Flying Arena at the University of Illinois Urbana-Champaign. The photorealistic 3D Gaussian Splat (3DGS) representations of these scenes, the ground truth nominal tracks,  and the code for rendering images from different camera poses are packaged as a benchmark with the released $\ART$ for others to use in robustness verification research tasks. 
%
 The scenes are generated using \emph{FalconGym}~\cite{falcon} and \emph{Nerfstudio}~\cite{nerfstudio} which enable creation and semantic editing of 3DGS scenes. The four tracks consist of racing gates arranged in distinct layouts as shown in Figure~\ref{fig:verify_tracks}.
%
 Each scene contains approximately 470k Gaussians.
% , while each gate is modeled by roughly 3k Gaussians.
 The four tracks consist of racing gates arranged in distinct layouts
 as shown in Figure~\ref{fig:verify_tracks}.

%\paragraph{Nominal trajectory.} 
For each track, a nominal flight trajectory is generated using \emph{Kochanek--Bartels (TCB) splines}~\cite{kochanek1984interpolating}, given the start pose, end pose, and the poses of the gates. The spline is discretized into a sequence of waypoints with a fixed spatial resolution of $\Delta t = 5\,\mathrm{cm}$.
%
%\paragraph{Pose space.} 
Around each waypoint, we define a local neighborhood parameterized as a cylindrical set with dimensions $(d, r, \theta)$, corresponding to length, radial displacement, and angular deviation, respectively. The cylinder length is defined by the vector from the current waypoint to the next  along the nominal trajectory. 
\sayan{Resume here.}
Within each cylindrical pose region, the camera orientation is constrained to align with the direction from the current waypoint toward the center of the subsequent gate. This design ensures that the target gate remains within the camera’s field of view throughout the perturbation range. The angular parameter spans the full circle, i.e., $\theta \in [0, 2\pi)$.

The cylinder radius is defined by a quadratic function of the waypoint’s relative distance to its neighboring gates: the radius is smaller when the waypoint is closer to a gate and increases as the waypoint moves farther from both the preceding and succeeding gates. Taken together, the pose space along a trajectory forms a tube-shaped region, with a total length ranging from 5 to 10 meters and a radius varying between 0.1 and 0.2 meters.

\paragraph{Pose Estimator.}
The \emph{GateNet-based pose estimator} is trained by uniformly sampling 1{,}000 poses from the defined pose space. The network takes abstract images of shape $(3, 64, 64)$ as input and outputs a three-dimensional vector representing the relative pose from the current waypoint to the center of the next gate, expressed in the waypoint coordinate frame. The estimated camera pose in the world coordinate frame is then obtained by applying the appropriate coordinate transformation using the waypoint pose.


\paragraph{Result Evualation.} We denote the input pose region by the interval $[p_l, p_u]$; the resulting estimated pose as $[\hat{p}_l, \hat{p}_u]$. A pose region is considered \emph{certified} if
\[
\max\bigl(p_u-\hat{p}_l,\; \hat{p}_u-p_l\bigr)
\leq 10\,\text{cm},
\]
meaning that, for any concrete pose within the input range, the corresponding estimated pose is guaranteed to remain within the predefined tolerance. Certified regions are visualized in green in Fig~\ref{fig:verify_tracks}. Otherwise, the region is marked in red in Fig~\ref{fig:verify_tracks}, indicating a potential violation where the pose estimation error may exceed the threshold.

This verification criterion is conservative due to several sources of over-approximation: (i) abstraction errors introduced by the abstract rendering pipeline, (ii) relaxation incurred when converting linear bounds into interval bounds, and (iii) the width of each pose space partition $p_u-p_l$. The first and third sources of over-approximation can be reduced by employing finer partitions, at the cost of increased computational time. The second source can be mitigated by enabling end-to-end linear bound propagation. The bottleneck is that, linear bound propagation through cumulative product operations exhibits complexity proportional to the input dimension, rendering it computationally prohibitive for scenes containing a large number of Gaussians.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/verfy_circle.png}%
    \hspace{0.02\textwidth}%
    \includegraphics[width=0.48\textwidth]{figures/verfy_line.png}
    
    \vspace{2mm}
    
    \includegraphics[width=0.48\textwidth]{figures/verfy_uturn.png}%
    \hspace{0.02\textwidth}%
    \includegraphics[width=0.48\textwidth]{figures/verfy_right.png}
    
    \caption{\small Verification results across different track layouts: (a) circular, (b) straight, (c) U-turn, and (d) right-angle tracks. Green indicates certified regions; red denotes potential violations; blue for gates.}
    \label{fig:verify_tracks}
\end{figure}

\paragraph{Hardware and Scalability.} All experiments are conducted on a workstation equipped with an NVIDIA GeForce RTX 4070 GPU with 16 GB of memory, using CUDA 12.2. Verifying the entire pose space across the four tracks requires approximately 10–11 hours of computation. This runtime is primarily constrained by GPU memory limitations, which restrict the number of Gaussians that can be processed simultaneously. As a result, scenes with a larger number of Gaussians incur higher computational costs. In addition, the number of pose space partitions significantly affects the overall runtime. Since the computational cost is almost irrelevant to the size of each partition width (although larger ranges may lead to increased over-approximation error through abstract rendering pipeline), increasing the number of partitions proportionally increases the total verification time.

\paragraph{Result Analysis. }The results shown in Figure~\ref{fig:verify_tracks} demonstrate the robustness of the Bound GateNet model across diverse track layouts. Certified regions (shown in green) dominate areas where the pose estimator remains within the predefined error bounds, indicating reliable performance over large portions of the pose space. In contrast, uncertified regions (shown in red) correspond to potential failure cases and tend to appear near gates where only a partial view of the upcoming gate is available. Pose estimation in these configurations is inherently challenging due to limited visual context, even without considering formal verification, which explains the increased frequency of verification failures in these regions.

