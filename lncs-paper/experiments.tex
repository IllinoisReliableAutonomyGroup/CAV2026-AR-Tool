\section{Experimental Evaluation}
\label{sec:experiments}

\paragraph{The racing benchmark.} We evaluate the \emph{Abstract Rendering Toolkit (ART)} by verifying the robustness of a pretrained GateNet-based pose estimator across four drone racing tracks constructed in the Flying Arena at the University of Illinois Urbana-Champaign. The photorealistic 3D Gaussian Splat (3DGS) representations of these scenes, the ground truth nominal tracks,  and the code for rendering images from different camera poses are packaged as a benchmark with the released $\ART$ for others to use in robustness verification research tasks. 
%
 The scenes are generated using \emph{FalconGym}~\cite{falcon} and \emph{Nerfstudio}~\cite{nerfstudio} which enable creation and semantic editing of 3DGS scenes. The four tracks consist of racing gates arranged in distinct layouts as shown in Figure~\ref{fig:verify_tracks}.
%
 Each scene contains approximately 470k Gaussians.
% , while each gate is modeled by roughly 3k Gaussians.
 The four tracks consist of racing gates arranged in distinct layouts
 as shown in Figure~\ref{fig:verify_tracks}.

%\paragraph{Nominal trajectory.} 
For each track, a nominal flight trajectory is generated using \emph{Kochanek--Bartels (TCB) splines}~\cite{kochanek1984interpolating}, given the start pose, end pose, and the poses of the gates. The spline is discretized into a sequence of waypoints with a fixed spatial resolution of $\Delta t = 5\,\mathrm{cm}$.
%
%\paragraph{Pose space.} 
The input pose space $P$ over which the robustness of the pose estimator is verified is defined by a sequence of local neighborhoods around each waypoint along the nominal trajectory.
The shape of this local neighborhood is designed to reflect the expected variations in drone pose during actual flight conditions. It is specified as a cylindrical set with  length $d$, radius $r$, and angular deviation $\theta$. Each cylinder's length $d$ is defined by the vector from the one waypoint to the next  along the nominal trajectory. 
%
The radius is a function of  the waypoint’s distance to neighboring gates. \sayan{For example, controllers it is expected that the drone will be near the center of a gate when passing through it, but may deviate more when it is farther away from gates. Thus, the radius is set to be smaller when the waypoint is close to a gate and larger when it is farther away from both the preceding and subsequent gates.} 
For each point in this cylindrical neighborhood,  the camera's pose rotation matrix $R\in SO(3)$ is constructed such that the forward direction of the waypoint aligns with the vector pointing toward the center of the next gate, ensuring that the gate remains within the camera’s field of view. The angular range spans the full circle, i.e., $\theta \in [0, 2\pi)$.
\sayan{What does the last sentence mean?}
An example pose space along a nominal trajectory and its cylindrical neighborhoods are illustrated in Figure~\ref{fig:verify_setup}. 
%
he pose space along a trajectory forms a tube-shaped region with a total length ranging from 5 to 10 meters and a radius between 0.1 and 0.2 meters.

\paragraph{Pose estimator.} The \emph{Bound GateNet} model is trained by sampling 1{,}000 poses from the defined pose space. The network takes an abstract image tensor of shape $(3, 64, 64)$ as input and outputs a three-dimensional vector representing the relative pose from the current waypoint to the center of the next gate, expressed in the waypoint coordinate frame. The estimated pose in the world coordinate frame is obtained by applying the corresponding rotation matrix $R$.

\paragraph{Result Evualation.} We denote the input pose region by the interval $[\underline{p}, \overline{p}]$. After abstract rendering, the resulting abstract images are fed into the \emph{Bound GateNet} model to compute interval bounds on the estimated pose, denoted as $[\underline{\hat{p}}, \overline{\hat{p}}]$. A pose region is considered \emph{certified} if
\[
\max\bigl(\overline{p}-\underline{\hat{p}},\; \overline{\hat{p}}-\underline{p}\bigr)
\leq 10\,\text{cm},
\]
meaning that, for any concrete pose within the input range, the corresponding estimated pose is guaranteed to remain within the predefined tolerance. Certified regions are visualized in green in Fig~\ref{fig:verify_tracks}. Otherwise, the region is marked in red, indicating a potential violation where the pose estimation error may exceed the threshold.

This verification criterion is conservative due to several sources of over-approximation: (i) abstraction errors introduced by the abstract rendering pipeline, (ii) relaxation incurred when converting linear bounds into interval bounds, and (iii) the finite partitioning of the pose space, which directly affects the width of $[\underline{p}, \overline{p}]$. The first and third sources of over-approximation can be reduced by employing finer partitions, at the cost of increased computational time. The second and third sources can be further mitigated by propagating linear bounds throughout the entire pipeline, allowing the estimated pose to be expressed as a linear function of the input pose. Such an approach would yield tighter certifications and improve verification precision.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/verfy_circle.png}%
    \hspace{0.02\textwidth}%
    \includegraphics[width=0.48\textwidth]{figures/verfy_line.png}
    
    \vspace{2mm}
    
    \includegraphics[width=0.48\textwidth]{figures/verfy_uturn.png}%
    \hspace{0.02\textwidth}%
    \includegraphics[width=0.48\textwidth]{figures/verfy_right.png}
    
    \caption{\small Verification results across different track layouts: (a) circular, (b) straight, (c) U-turn, and (d) right-angle tracks. Green indicates certified regions; red denotes potential violations; blue for gates.}
    \label{fig:verify_tracks}
\end{figure}

\paragraph{Hardware and Scalability.} All experiments are conducted on a workstation equipped with an NVIDIA GeForce RTX 4070 GPU with 16 GB of memory, using CUDA 12.2. Verifying the entire pose space across the four evaluated scenes requires approximately 10–11 hours of computation. This runtime is primarily constrained by GPU memory limitations, which restrict the number of Gaussians that can be processed simultaneously. As a result, scenes with a larger number of Gaussians incur higher computational costs. In addition, the number of pose-space partitions significantly affects the overall runtime. While the computational cost is relatively insensitive to the size of each individual input range (although larger ranges may lead to increased over-approximation error), increasing the number of partitions proportionally increases the total verification time.

\paragraph{Verification Results and Analysis. }The results shown in Figure~\ref{fig:verify_tracks} demonstrate the robustness of the Bound GateNet model across diverse track layouts. Certified regions (shown in green) dominate areas where the pose estimator remains within the predefined error bounds, indicating reliable performance over large portions of the pose space. In contrast, uncertified regions (shown in red) correspond to potential failure cases and tend to appear near gates where only a partial view of the upcoming gate is available. Pose estimation in these configurations is inherently challenging due to limited visual context, even without considering formal verification, which explains the increased frequency of verification failures in these regions.

