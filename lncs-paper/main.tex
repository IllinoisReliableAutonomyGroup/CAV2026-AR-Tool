\documentclass[runningheads]{llncs}

\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{positioning,arrows.meta,calc}

\input{macros}

\begin{document}

\title{Abstract Rendering Toolkit for}
\author{Author Name}
\institute{Your Institution}

\maketitle

\begin{abstract}
    Abstract rendering over-approximates the set of images produced by uncertain poses and scenes, enabling end-to-end robustness claims for vision pipelines. We present \ART, a toolkit that turns this idea into a reproducible formal-verification workflow. Users describe a bounded subset of \(SE(3)\) as a tube of cylinders along a nominal trajectory (JSON) and provide scene, camera, and partitioning options in a short YAML file. \ART\ then (i) validates the pose tube, (ii) partitions pose/scene space anisotropically, (iii) runs abstract rendering on each cell and caches per-pixel bounds, and (iv) invokes a bound-propagation verifier (CROWN) on the cached abstract images, storing per-cell verdicts. The cached “AR” and “verification” dictionaries share keys, making failures traceable to their rendering evidence and eliminating reruns when models change. We demonstrate \ART\ on vision-based pose estimation for drone racing (GateNet) across four 3D Gaussian Splat tracks ($\approx$470k Gaussians each); a full verification sweep completes in $10–11$ hours on a single RTX 4070. All code, scenes, and scripts are released to support artifact evaluation and future verification research on vision-centric autonomy.
\end{abstract}

\input{introduction.tex}

\input{background.tex}

\input{tool.tex}

\input{experiments.tex}

\section{Discussion}
\label{sec:discusion}


\section{Conclusion}
\label{sec:conclusion}
\sayan{Write later.}

Future directions: Linear set representations for tighter bounds. 



\bibliographystyle{splncs04}
\bibliography{egbib}
\end{document}
